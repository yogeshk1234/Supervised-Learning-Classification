{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1FrUrE1bb_Tl3Qew0sfm_WWV3CuYbNfGI","timestamp":1685105036258},{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1685002764649}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1><b>Project Type - Supervised Machine learning (Classification Model)\n","<h1><b>Contribution - Individual"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["<h1><b>Project Summary\n","\n","\n","* This project aimed to help an insurance company expand its business by offering vehicle insurance to its existing health insurance customers. The company wanted to find out which customers were likely to be interested in buying vehicle insurance. They collected data on their past customers and used it to build a predictive model.\n","\n","* The first step was to clean and explore the data. They made sure there were no duplicate or empty values in the data, and they organized the data in a way that could be easily analyzed. They also looked for any patterns or trends in the data through exploratory analysis. They discovered that a higher number of interested customers were male.\n","\n","* To create the predictive model, they compared four different machine learning algorithms: Logistic Regression, K-Nearest Neighbors, Random Forest, and XGBoost. They used various metrics to evaluate the models' performance, including accuracy, precision, recall, F1-score, average precision, and ROC AUC score. They also fine-tuned the models using hyperparameter tuning to improve their performance.\n","\n","* The dataset used in the study had information on 381,109 customers and 12 features. They conducted feature engineering to handle missing values, outliers, and correlations between features. They also transformed categorical variables into numerical ones. The dataset was split into a training set and a testing set, with a ratio of 70:30.\n","\n","* After evaluating the four machine learning algorithms, it was found that Gradient Boosting provided the best overall performance in terms of accuracy, precision, recall, and F1 score. The Gradient Boosting algorithm achieved an accuracy of 84% and an average precision, recall, and F1 score of 84%, 85%, and 84%, respectively. It also achieved a ROC AUC score of 84%. While other algorithms such as Random Forest, XGBoost, KNN, and Logistic Regression performed well with accuracy scores ranging from 80% to 82%, they did not outperform the Gradient Boosting algorithm.\n","\n","* These results suggest that the Gradient Boosting algorithm is effective in predicting customer interest in vehicle insurance. The predictive model can be used to target marketing campaigns towards potential customers. Overall, the project showed how machine learning algorithms can help identify potential customers and expand a business's customer base."],"metadata":{"id":"RV_2UHa2FJ9O"}},{"cell_type":"markdown","source":["<h1><b>Business Context\n","\n","* Vehicle insurance is similar to medical insurance, but instead of covering medical expenses, it covers damages related to vehicles. Every year, customers pay a premium amount to an insurance company. In case of an accident or any unfortunate event involving the insured vehicle, the insurance company provides compensation, known as the \"sum assured,\" to the customer.\n","\n","* Now, the insurance company wants to develop a model that can predict whether a customer would be interested in purchasing vehicle insurance. By understanding which customers are more likely to be interested, the company can create targeted communication strategies to reach out to them. This will help the company optimize its business model and increase its revenue.\n","\n","* By building a predictive model using customer data, such as demographics, vehicle details, and policy information, the company can predict the likelihood of a customer being interested in vehicle insurance. This model will enable the company to focus its communication efforts on those customers who are more likely to be interested in purchasing insurance. By reaching out to the right customers, the company can improve its business model and increase its revenue by selling more vehicle insurance policies.\n","\n","\n","\n","\n"],"metadata":{"id":"K5utcOggFEbk"}},{"cell_type":"markdown","source":["<h1><b>Problem Statement\n"," \n","* The goal of this project is to predict whether customers are interested in buying vehicle insurance using a dataset that contains information about 381,109 customers and 12 different characteristics. These characteristics include details about demographics like gender, age, and region, as well as information about vehicles such as their age and damage history. The dataset also includes information about the insurance policy, such as the premium amount and how the customer learned about the insurance.\n","\n","* The main focus is on the \"Response\" column, which indicates whether a customer is interested in buying vehicle insurance or not. This is the variable we want to predict accurately.\n","\n","* The aim is to develop a model that can analyze the given information about each customer and predict their interest in vehicle insurance. By training the model on this dataset and utilizing various machine learning techniques, we can build a predictive model that will be able to identify potential customers who are likely to be interested in purchasing vehicle insurance.\n","\n","* The ultimate goal is to use this predictive model to target marketing efforts towards those customers who are most likely to be interested in vehicle insurance, thus increasing the efficiency and effectiveness of the insurance company's marketing strategy."],"metadata":{"id":"nCW8Ft5YEsvH"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"CfZqiGjSetlE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Importing Visualization Libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from xgboost import XGBRFClassifier\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n","\n","\n","# Importing warning for ignore warnings \n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","df=pd.read_csv(\"/content/drive/MyDrive/capstone project 3/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv\")\n","df"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# making a copy of data for safity purpose\n","df_copy = df.copy()\n"],"metadata":{"id":"UlPxcryWgY_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","print(len(df[df.duplicated()]))"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isna().sum().sort_values(ascending= False).reset_index().rename(columns={'index':'Columns',0:'Null values'})"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","plt.figure(figsize=(14, 5))\n","sns.heatmap(df.isnull(), cmap='viridis', yticklabels=False)\n","plt.xlabel(\"column_name\", size=14, weight=\"bold\")\n","plt.title(\"Missing Values in Column\",fontweight=\"bold\",size=17)\n","plt.show()"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Attribute De"],"metadata":{"id":"zj-2UoTykOuo"}},{"cell_type":"code","source":[],"metadata":{"id":"CvjS1HHgkBrX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1><b>Variable Description\n","\n",">id: Unique ID for the customer\n","\n",">Gender : Gender of the customer\n","\n",">Age : Age of the customer\n","\n",">Driving_License : 0 = Customer does not have DL, 1 = Customer already has DL\n","\n",">Region_Code : Unique code for the region of the customer\n","\n",">Previously_Insured : 1 = Customer already has Vehicle Insurance, 0 = Customer doesn't have Vehicle Insurance\n","\n",">Vehicle_Age : Age of the Vehicle\n","\n",">Vehicle_Damage : 1 = Customer got his/her vehicle damaged in the past. 0 = Customer didn't get his/her vehicle damaged in the past.\n","\n",">Annual_Premium : The amount customer needs to pay as premium in the year\n","\n",">Policy Sales Channel : Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n","\n",">Vintage : Number of Days, Customer has been associated with the company\n","\n",">Response : 1 : Customer is interested, 0 : Customer is not interested"],"metadata":{"id":"jj5Nv_4zklS0"}},{"cell_type":"code","source":["# Dataset Describe\n","df.describe(include=\"all\")"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","df.nunique().reset_index().rename(columns={'index':'Columns',0:'Unique values'})"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":[">Data wrangling (Also known as data munging) is the practice of cleansing, restructuring, and enriching raw data. This process is very critical for businesses to perform because it is the only method that makes raw data usable.\n","\n",">Raw data is complex because it has not been processed or integrated into a system. With data wrangling, these records are transformed into a standard format that helps highlight valuable insights. The process entails consolidating data into one location and rectifying any missing information or errors.\n"],"metadata":{"id":"Gpw_jaWZog5G"}},{"cell_type":"markdown","source":["<h1>Drop all column that is not required for our analysis"],"metadata":{"id":"wF9BLar-pYwU"}},{"cell_type":"code","source":["# drop Id columns \n","df.drop('id',inplace=True,axis=1)"],"metadata":{"id":"Qm5fuXlxpob8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1>Extrect numerical and categorical column"],"metadata":{"id":"_AqgZZfbpwkQ"}},{"cell_type":"code","source":["# make a function to extract categorical and numerical columns\n","def extract_cat_num(df):\n","  '''\n","  This function extract categorocal and Numerical columns in dataset\n","  '''\n","\n","  cat_col=[col for col in df.columns if df[col].dtype=='object']\n","  num_col=[col for col in df.columns if df[col].dtype!='object']\n","  return cat_col,num_col"],"metadata":{"id":"O1lkKjFop4Hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_col,num_col=extract_cat_num(df)"],"metadata":{"id":"qzN97rLZqCI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.nunique()"],"metadata":{"id":"nf_0YqSorvei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fetch unique value in categorical feature columns\n","\n","for col in cat_col:\n","  print('{} has {} values'.format(col,df[col].unique()))\n","  print('\\n')"],"metadata":{"id":"Gdwh-6geqD62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1>Visualized categorical columns"],"metadata":{"id":"oSfhmLjTr5Rn"}},{"cell_type":"code","source":["plt.figure(figsize=(20,4),dpi=200)\n","\n","for i,feature in enumerate(cat_col):\n","  plt.subplot(1,3,i+1)\n","  sns.countplot(x=df[feature])\n","  plt.title(feature,fontsize=16,color='red')"],"metadata":{"id":"u-t9Yz1fqR-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fetch numerical columns \n","num_col"],"metadata":{"id":"ZxcdKl7it9s_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1>Visualized numerical column"],"metadata":{"id":"bcwP-R5guADM"}},{"cell_type":"code","source":["plt.figure(figsize=(10,6),dpi=200)\n","\n","for i,feature in enumerate(num_col):\n","  plt.subplot(3,3,i+1)\n","  df[feature].hist()\n","  plt.title(feature, fontsize=12,color='red')\n","  plt.tight_layout()"],"metadata":{"id":"gh8u97UOuFso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check data types \n","df.dtypes"],"metadata":{"id":"dX-F86OQuOK0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###<h1> What all manipulations have you done and insights you found?\n","\n",">Dropped the id column\n","\n",">All attributes don't have any discrepancy, so no need to correct any attribute column.\n","\n",">Categorical columns are: Gender, Vehicle_Age, Vehicle_Damage\n","\n",">Numerical columns are: Age, driving_License, Response Previously_InsuredRegion_Code, Annual_Premium, Policy_Sales_Channel, Vintage\n","\n",">Response attribute is our Output"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["####<h1> Chart - 1        Pie chart on dependant variable"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","\n","df['Response'].value_counts().plot(kind='pie',figsize=(15,6), autopct=\"%1.1f%%\",shadow=False,labels=['Non_Interested(%)','Interested(%)'])\n","plt.title('Response of customers',color='red');\n","\n","# count of Target variable\n","df['Response'].value_counts()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<h1> 1. Why did you pick the specific chart?\n","\n",">A pie chart is a useful tool to display the distribution of various categories in a dataset. By dividing the circle into proportional sections, each representing a different category, the pie chart allows for a clear comparison of the relative size of each category. The use of different colors for each section further enhances the clarity of the representation and makes it easier to understand and interpret the data."],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["#####<h1> 2. What is/are the insight(s) found from the chart?\n","\n",">The data shows that a large majority (87.7%) of customers are not interested, while a smaller portion (12.3%) are interested. The response variable is imbalanced with more instances of \"not interested\" than \"interested\"."],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["#####<h1> 3. Will the gained insights help creating a positive business impact? \n","<h3>Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","\n",">It depends on the specific business scenario and the insights that were gained from the pie chart. The pie chart provides information on the proportion of different categories in a dataset, but it is up to the business to use that information in a meaningful way to drive positive impact.\n","\n",">For example, if the pie chart showed a large proportion of customers who were not interested, the business could use that information to identify areas for improvement and increase customer engagement. On the other hand, if the pie chart showed a large proportion of customers who were interested, the business could capitalize on that by focusing on maintaining and growing that customer base.\n","\n",">Ultimately, the impact will depend on how the insights are applied and acted upon by the business."],"metadata":{"id":"X-eQiRY8wCBb"}},{"cell_type":"markdown","source":["####<h1> Chart - 2    Visualized categorical variable with target *variable*"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","\n","# distribution of categorical variables in the dataset\n","\n","plt.figure(figsize=(20,6),dpi=200)\n","\n","for i, feature in enumerate(cat_col):\n","  plt.subplot(1, len(cat_col), i+1)\n","  sns.countplot(x=df[feature], hue='Response', data=df)\n","  plt.title(feature, fontsize=16, color='red')\n","  plt.tight_layout()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<h1> 1. Why did you pick the specific chart?\n","\n",">A count plot, also referred to as a bar plot, is a visualization technique that displays the frequency of each category in a categorical or nominal variable. The frequency counts are represented as bars, making it simple to understand the distribution of values in the dataset. Furthermore, the y-axis can be adjusted to show not just the count, but also other statistics such as the percentage of total values for each category. This additional information helps to provide deeper insights into the data and facilitates easy comparison of the proportions of different categories."],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["#####<h1> 2. What is/are the insight(s) found from the chart?\n","\n",">The statement \"Male are more interested in vehicle insurance than female\" can be confirmed by checking the count of males and females in the bar plot of the feature representing gender.\n","\n",">The statement \"In term of vehicle_age, vehicle_age of 1-2 year are more interested in insurance followed by < 1 year and >2 years\" can be confirmed by checking the count of each vehicle age category in the bar plot of the feature representing vehicle age.\n","\n",">The statement \"Customers having Vehicle_damage are more interested in insurance\" can be confirmed by checking the count of customers with and without vehicle damage in the bar plot of the feature representing vehicle damage"],"metadata":{"id":"RoZysFyqw8Dj"}},{"cell_type":"markdown","source":["#####<h1> 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n",">If the goal is to target customers who are more likely to purchase insurance.\n","\n",">The insights gained from the plots indicating that male customers and customers with 1-2 year old vehicles are more interested in insurance could inform targeted marketing efforts."],"metadata":{"id":"ggJS7CRxxdIV"}},{"cell_type":"markdown","source":["####<h1> Chart - 3 Continuous variable with tagret variable"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","\n","# checking Outliers in numeric features using seaborn boxplot\n","\n","# list of continuous columns in dataset\n","\n","list=['Age','Region_Code','Annual_Premium','Policy_Sales_Channel','Vintage']\n","\n","plt.figure(figsize=(12,6), dpi=200)\n","\n","for i, feature in enumerate(list):\n","    plt.subplot(2, 3, i+1)\n","    sns.boxplot(x='Response', y=df[feature], data=df)\n","    plt.title(feature, fontsize=16, color='red')\n","\n","plt.tight_layout()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<h1> 1. Why did you pick the specific chart?\n","\n",">A box plot, or box and whisker plot, is a visualization technique used to show the distribution of continuous data, not categorical data. The plot displays information about the shape of the distribution, including the median, quartiles, and outliers. The box of the plot displays the interquartile range (IQR), which represents the range between the first and third quartiles (25th and 75th percentiles), while the whiskers extend to the minimum and maximum values, excluding outliers. Outliers are plotted as individual points outside of the whiskers.\n","\n",">The box plot provides a concise summary of the data, making it useful for comparing distributions across different groups or for identifying potential outliers or skewness in the data. However, it is not suitable for visualizing categorical or nominal data. For categorical data, you would typically use a bar plot instead."],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["#####<h1> 2. What is/are the insight(s) found from the chart?\n","\n",">This code creates a figure with multiple subplots, each showing the relationship between a continuous feature and the target variable Response. The sns.boxplot function is used to plot the features, with the box plot showing any potential outliers in the data. The target variable Response is used to color the boxes, allowing for a visual assessment of the relationship between the feature and the target variable.\n","\n","From the description, it seems that only the Annual_Premium feature has outliers, which may have an impact on the performance of machine learning algorithms. It's important to consider this when selecting or preprocessing features for modeling.\n","\n"],"metadata":{"id":"Gmp4HVBSySen"}},{"cell_type":"markdown","source":["#####<h1> 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n",">The insights lead to informed decisions and effective strategies, they have the potential to drive positive business impact."],"metadata":{"id":"GwqEdItHyscS"}},{"cell_type":"markdown","source":["####<h1> Chart - 4  Distplot with all numerical column with target variable\n"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","\n","plt.figure(figsize = (16, 16))\n","plt.suptitle(\"Analysis Of Variable Response\",fontweight=\"bold\", fontsize=20)\n","\n","plt.subplot(4,3,1)\n","sns.kdeplot(x='Age', hue='Response', palette = 'Set2', shade=True, data=df)\n","\n","plt.subplot(4,3,2)\n","sns.kdeplot(x='Region_Code', hue='Response', palette = 'Set2', shade=True, data=df)\n","\n","plt.subplot(4,3,3)\n","sns.kdeplot(x='Annual_Premium', hue='Response', palette = 'Set2', shade=True, data=df)\n","\n","plt.subplot(4,3,4)\n","sns.kdeplot(x='Policy_Sales_Channel', hue='Response', palette = 'Set2', shade=True, data=df)\n","\n","plt.subplot(4,3,5)\n","sns.kdeplot(x='Vintage', hue='Response', palette = 'Set2', shade=True, data=df)\n"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<h1> 1. Why did you pick the specific chart?\n","\n",">Display a univariate or bivariate distribution using a histogram, kernel density estimation, or rug plot. Displots are available in the seaborn library in Python and are useful for visualizing the distribution of data."],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["#####<h1> 2. What is/are the insight(s) found from the chart?\n","\n",">From this insights, we came to know that there are Age and Annual_premium are positively skewed."],"metadata":{"id":"u5JKnqwUzQ3U"}},{"cell_type":"markdown","source":["####<h1> Chart - 5 Relationship between age and target variable"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","#Age VS Response\n","plt.figure(figsize=(20,10))\n","sns.countplot(x='Age',hue='Response',data=df);\n","plt.tight_layout()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<h1> 1. Why did you pick the specific chart?\n","\n",">This interpretation of the graph is based on the assumption that the height of the bars represents the number of people who are interested in vehicle insurance, and the x-axis categories represent different age groups. Based on the description given, it seems that the 20-30 age group has a higher count of people who are interested in vehicle insurance compared to 50+ age groups, although the 30-50 age group has the highest overall interest in vehicle insurance."],"metadata":{"id":"lEJkIqat0wN9"}},{"cell_type":"markdown","source":["#####<h1> 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n",">If the target audience for vehicle insurance is primarily in the 20-30 age and 30-50 age group.\n"],"metadata":{"id":"SZYpjpeQ1B9c"}},{"cell_type":"markdown","source":["#####<h1><b>Hypothesis Testing<h1>\n","\n","\n",">The null hypothesis (H0): would be that there is no relationship between the predictors and the response variable (vehicle insurance purchase).\n","\n",">Alternative hypothesis (Ha): would be that there is a relationship between the predictors and the response variable."],"metadata":{"id":"BtnNnn932If_"}},{"cell_type":"code","source":["# performing the independant t test on numerical varialbe\n","import scipy.stats as stats\n","\n","# make a dataframe\n","tstats_df= pd.DataFrame()\n","\n","# run a loop for all numerical variable\n","for i in num_col:\n","  tstats= stats.ttest_ind(df.loc[df['Response']==1,i],df.loc[df['Response']==0,i])\n","  temp= pd.DataFrame([i,tstats[0],tstats[1]]).T\n","  temp.columns=['Variable Name','T-statstic','P-value']\n","  tstats_df=pd.concat([tstats_df,temp],axis=0,ignore_index=True)\n","\n","tstats_df=tstats_df.sort_values(by='P-value').reset_index(drop=True)\n","tstats_df"],"metadata":{"id":"7aXMSHd623Ni"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">Variables and their P-value\n","\n","Here our level of significance(alpha ) is 0.05. we got variable id,Vintage, which are not significance so we reject the null hypothesis."],"metadata":{"id":"8OuyRsrS28Mc"}},{"cell_type":"markdown","source":["#####<h1><b>Feature Engenerring<h1><b>"],"metadata":{"id":"xyg4Iu1J3DJQ"}},{"cell_type":"code","source":["df.types"],"metadata":{"id":"EqwExnsu3Q_c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>convert variable to appropriate datatypes :-\n","\n"," <H4>changing categorical value to numerical value"],"metadata":{"id":"DDgnjO9h3WWx"}},{"cell_type":"code","source":["# Assume vehicle_Age as an ordinal categorical \n","\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","# Define the ordering of categories\n","age_ordering = ['< 1 Year', '1-2 Year', '> 2 Years']\n","\n","# Create an ordinal encoder with the specified ordering\n","encoder = OrdinalEncoder(categories=[age_ordering])\n","\n","# Fit and transform the encoder on the 'Vehicle_Age' column in train_df\n","df['Vehicle_Age'] = encoder.fit_transform(df[['Vehicle_Age']])"],"metadata":{"id":"Z9IL6CCR4OqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OneHotEncoding using pandas (Gender and Vehicle_Damage as a nominal category)\n","\n","df=pd.get_dummies(df,columns=['Gender','Vehicle_Damage'],drop_first=True)"],"metadata":{"id":"9TIc3-L94RYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"HI6pjSo54Sec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1><b>Handling Outlier"],"metadata":{"id":"coPTAfze4iz4"}},{"cell_type":"code","source":["# Visualizing the outlier using boxplot\n","\n","plt.figure(figsize=(10,5))\n","sns.boxplot(y='Annual_Premium',x='Response',data=df )"],"metadata":{"id":"46dWMQ4_4rNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the variation of Annual_Premium using rugplot\n","\n","plt.figure(figsize=(20,4),dpi=200)\n","sns.rugplot(y='Response',x='Annual_Premium',data=df);\n"],"metadata":{"id":"1or0ISYm4uvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of row having Annual_Premium >140000\n","\n","outliers = df.loc[df['Annual_Premium']>135000]\n","outliers.shape"],"metadata":{"id":"Hw1lX9Ui4xd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop row having Annual_Premium >140000\n","df = df[df['Annual_Premium']<=135000]\n","df.shape"],"metadata":{"id":"N5IgNZQL4zww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# again Visualizing the outlier\n","\n","plt.figure(figsize=(10,5))\n","sns.boxplot(y='Annual_Premium',x='Response',data=df );"],"metadata":{"id":"PzlPjAjj42mK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20,4),dpi=200)\n","sns.rugplot(y='Response',x='Annual_Premium',data=df)"],"metadata":{"id":"6cvQDI4k45VE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">Removing outliers from the dataset can have an effect on the model performance. If the outliers are affecting the model negatively, i.e., increasing the error rate or bias, removing them may improve the model performance by reducing the error rate or bias."],"metadata":{"id":"U6k8E0S748Zk"}},{"cell_type":"markdown","source":["<h1><b>Check Correlation and Multicollinearity between features\n","\n",">When performing feature selection in machine learning, it is recommended to perform correlation analysis first to identify highly correlated features. Once this analysis is complete, a variety of feature selection techniques can be used to identify the most important features."],"metadata":{"id":"ju-cbqt25Cjb"}},{"cell_type":"code","source":["df.head(5)"],"metadata":{"id":"594p4ojE5XFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr=df.corr().round(2)\n","plt.figure(figsize=(10,4),dpi=200)\n","sns.heatmap(corr,annot=True,cmap = 'YlOrBr')\n","plt.title('Correlation between all the variables', size=16)\n","plt.show()"],"metadata":{"id":"9GLZx9q35Y59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","# Function to calculate Multicollinearity\n","def calc_vif(X):\n","\n","  # VIF dataframe\n","  vif = pd.DataFrame()\n","  vif[\"feature\"] = df.columns\n","  \n","  # calculating VIF for each feature\n","  vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n","  return(vif)"],"metadata":{"id":"MfrBfpDQ5gjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calc_vif(df)"],"metadata":{"id":"L7v0UibC5jFd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=df.drop('Driving_License',axis=1)"],"metadata":{"id":"do6aboUY5lpr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr=df.corr().round(2)\n","plt.figure(figsize=(10,4),dpi=200)\n","sns.heatmap(corr,annot=True,cmap = 'YlOrBr')\n","plt.title('Correlation between all the variables', size=16)\n","plt.show()"],"metadata":{"id":"fkKuXH775n72"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","# Function to calculate Multicollinearity\n","def calc_vif(X):\n","\n","  # VIF dataframe\n","  vif = pd.DataFrame()\n","  vif[\"feature\"] = df.columns\n","  \n","  # calculating VIF for each feature\n","  vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n","  return(vif)"],"metadata":{"id":"Dm1xO-gQ5q7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calc_vif(df)"],"metadata":{"id":"vp1WOcwC5uPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>Select best feature of your model"],"metadata":{"id":"bCyCFYSB5yAR"}},{"cell_type":"code","source":["#separating the dependent and independent variables\n","\n","X=df.drop(columns='Response')\n","y=df['Response']"],"metadata":{"id":"F18d-hjR57qN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2"],"metadata":{"id":"vHzX-squ5-gV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ordered_rank_features = SelectKBest(score_func=chi2,k=9)\n","ordered_feature = ordered_rank_features.fit(X,y)"],"metadata":{"id":"2jLoekI-6AxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check score of all feature\n","\n","ordered_feature.scores_"],"metadata":{"id":"2JsWyVie6DIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make dataframe and store in a variable\n","\n","datascores = pd.DataFrame(ordered_feature.scores_, columns=['Score'])"],"metadata":{"id":"Twy-EXQ26F8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datascores"],"metadata":{"id":"CK-ZhQYj6IfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make dataframe from X_train and store in variable\n","\n","dfcols = pd.DataFrame(X.columns)"],"metadata":{"id":"AM74kYJc6LFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# concatinate both dataframe\n","\n","pd.concat([dfcols, datascores],axis=1)\n","\n","features_rank = pd.concat([dfcols, datascores],axis=1)"],"metadata":{"id":"vK2k9FJ16Nx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features_rank"],"metadata":{"id":"9y_4weVq6P6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# give column name to feature_rank dataframe\n","\n","features_rank.columns = ['feature','score']"],"metadata":{"id":"jh-HwGr96SVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fetch top 8 features based on score\n"," \n","features_rank.nlargest(8,'score')"],"metadata":{"id":"rhuQ_kJT6U0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selected_columns = features_rank.nlargest(8,'score')['feature'].values"],"metadata":{"id":"hr-xv7S16XhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selected_columns"],"metadata":{"id":"t8p-vqga6Z-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_new = X[selected_columns]"],"metadata":{"id":"wiOEyFUW6cNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# final independent feature look\n","\n","X_new.head()"],"metadata":{"id":"iVjMWVkV6ejT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1><b>Data imbalanced Handling"],"metadata":{"id":"SCaQ_Nvq6hY-"}},{"cell_type":"code","source":["# Dependant Column Value Counts\n","print(df.Response.value_counts())\n","print(\" \")\n","\n","# Dependant Variable Column Visualization\n","df['Response'].value_counts().plot(kind='pie',\n","                              figsize=(15,6),\n","                               autopct=\"%1.1f%%\",\n","                               startangle=90,\n","                               shadow=True,\n","                               labels=['Not-Interested(%)','Interested(%)'],\n","                               colors=['skyblue','red'],\n","                               explode=[0,0]\n","                              )"],"metadata":{"id":"JpCUFJtZ6okr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>Do you think the dataset is imbalanced? Explain Why\n","\n",">Dependent column data ratio is 88:12. So, during model creating it's obvios that there will be bias and having a great chance of predicting the majority one so frequently. SO the dataset should be balanced before it going for the model creation part."],"metadata":{"id":"aVfkPXEC6tPV"}},{"cell_type":"code","source":["# Handaling imbalance dataset using SMOTE\n","\n","#importing SMote to make our dataset balanced\n","from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE()\n","\n","# fit predictor and target variable\n","X_smote, y_smote = smote.fit_resample(X_new,y)\n","\n","print('Original dataset shape {} \\n Resampled dataset shape {}'.format(len(df),len(y_smote)))"],"metadata":{"id":"Btkd9lfK7Bb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)\n","\n","SMOTE (Synthetic Minority Over-sampling technique) used for balanced the 88:12 dataset.\n","\n"," >SMOTE is a technique in machine learning for dealing with issues that arise when working with an unbalanced data set. In practice, unbalanced data sets are common and most ML algorithms are highly prone to unbalanced data so we need to improve their performance by using techniques like SMOTE.\n","\n"," >SMOTE is a data augmentation algorithm that creates synthetic data points from raw data. SMOTE can be thought of as a more sophisticated version of oversampling or a specific data augmentation algorithm.\n","\n"," >SMOTE has the advantage of not creating duplicate data points, but rather synthetic data points that differ slightly from the original data points. SMOTE is a superior oversampling option.\n","\n"," >That's why for lots of advantages, I have used SMOTE technique for balancinmg the dataset."],"metadata":{"id":"xeExMOA87GU5"}},{"cell_type":"code","source":["X_new.shape"],"metadata":{"id":"0Ll2nPAn7h_J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2><b>Data Spliting"],"metadata":{"id":"dbooxwGR7koH"}},{"cell_type":"code","source":["# Dividing the dataset into train and test set\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X_smote,y_smote,test_size=0.3,random_state=0)"],"metadata":{"id":"2By19FEd7pXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>What data splitting ratio have you used and why?\n","\n",">Dividing the data into training and testing sets is a common approach in machine learning to evaluate the performance of a model. The idea is to use the training data to estimate the parameters of the model, and the testing data to evaluate the performance of the model on new, unseen data.\n","\n",">By dividing the data into an 80/20 ratio, you are following the Pareto principle, which states that 80% of the effects come from 20% of the causes. In this case, the 80% of the data is used for training, and 20% is used for testing. This split ensures that you have enough data to accurately estimate the parameters of the model while also having enough data to accurately evaluate its performance.\n","\n",">However, it's important to note that the choice of split ratio (80/20 or any other) depends on the size of your dataset and the complexity of your model. If you have a large dataset, you may be able to use a smaller ratio (e.g., 70/30), while if you have a small dataset, you may need to use a larger ratio (e.g., 90/10).\n","\n",">In general, the goal is to find the right balance between the variance of the parameter estimates and the variance of the performance statistics, so that neither is too high. Therefore, I choose 70:30 ratio."],"metadata":{"id":"NN_wpcER7ulO"}},{"cell_type":"markdown","source":["<h1><b>Data Scaling"],"metadata":{"id":"geNkFojN8CPY"}},{"cell_type":"code","source":["# Scaling your data\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","X_train= scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"I_hJ8r7W8GQn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>Which method have you used to scale you data and why?\n","\n",">I used MinMaxscaler as it preserves the shape of the original distribution. Note that MinMaxScaler doesn't reduce the importance of outliers. The default range for the feature returned by MinMaxScaler is 0 to 1."],"metadata":{"id":"laH4nBl28I8V"}},{"cell_type":"markdown","source":["<h1><b>Model Implimentation\n","\n","The following algorithms are used in ML implemenation\n","\n","1.Logistic Regression\n","\n","2.k_nearest neighbours\n","\n","3.RandomForestClassifier\n","\n","4.XGB boostclassifier"],"metadata":{"id":"a2vsmVwW8WN-"}},{"cell_type":"markdown","source":["<h2><b> 1.Apply Logistic Regression:"],"metadata":{"id":"deqkbTAX8j1g"}},{"cell_type":"code","source":["# Model Implementation\n","clf = LogisticRegression(fit_intercept=True, max_iter=10000)\n","\n","# Fit the Algorithm\n","clf.fit(X_train, y_train)"],"metadata":{"id":"xpLWl3Fz8yNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking the coefficients\n","clf.coef_"],"metadata":{"id":"7jMUkb_h8zBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking the intercept value\n","clf.intercept_"],"metadata":{"id":"uPZlzTWn81Pm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on the model\n","# Get the predicted probabilities\n","train_preds = clf.predict_proba(X_train)\n","test_preds = clf.predict_proba(X_test)"],"metadata":{"id":"2GGo-Cvh83ts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the predicted classes\n","train_class_preds = clf.predict(X_train)\n","test_class_preds = clf.predict(X_test)"],"metadata":{"id":"otJcKTPn854p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the accuracy scores\n","train_accuracy = accuracy_score(train_class_preds,y_train)\n","test_accuracy = accuracy_score(test_class_preds,y_test)\n","\n","print(\"The accuracy on train data is \", train_accuracy)\n","print(\"The accuracy on test data is \", test_accuracy)"],"metadata":{"id":"dLwaLV0Q88G2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"61K3LFIr9CLB"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","\n","#  confusion matrix for train \n","labels = ['Not_Interested', 'Interested']\n","cm = confusion_matrix(y_train, train_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)\n"],"metadata":{"id":"w1FleEFt9Eku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the confusion matrix for test\n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_test, test_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"9ARMdwRg9JkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"gK0kTrAb9MdK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"nFNRhwOD9Pg-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Based on the results of the Logistic Regression algorithm\n","\n",">The classifier has a high precision (93%) for the \"Interested\" class, which means that the classifier correctly predicted a high percentage of positive instances among all predicted positive instances. However, it has a lower recall (72%), which means that the classifier missed a significant number of actual positive instances.\n","\n",">The overall accuracy, average precision, recall, and F1-score are all similar (78-79% accuracy and 79% average precision, 82% recall, and 78% F1-score). This indicates that the model is performing moderately well, but it is not excellent. The high average precision suggests that the model has a low false positive rate.\n","\n",">The ROC AUC score is 78%, which indicates that the model's ability to distinguish between positive and negative classes is moderate.\n","\n",">The classifier can be improved with hyperparameter tuning."],"metadata":{"id":"iGt5WCSE9cIt"}},{"cell_type":"markdown","source":["2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"gzBqjK7U9rW5"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV)\n","logistic = LogisticRegression(max_iter=100)\n","solvers = ['lbfgs']\n","penalty = ['10','l2','14','16','20','18']\n","c_values = [1000,100, 10, 1.0, 0.1, 0.01,0.001]\n","\n","# define grid search\n","grid = dict(solver=solvers,penalty=penalty,C=c_values)\n","\n","# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","grid_search = GridSearchCV(logistic, param_grid=grid, n_jobs=-1, cv=5, scoring='f1',error_score=0)\n","\n","# Fit the Algorithm\n","grid_result=grid_search.fit(X_train, y_train)\n","\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","\n","\n","# Predict on the model\n","# Get the predicted classes\n","train_class_preds = grid_result.predict(X_train)\n","test_class_preds = grid_result.predict(X_test)"],"metadata":{"id":"yIe4QkcQ9si9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for train data\n","lr_train_roc=roc_auc_score(y_train, train_class_preds)\n","lr_train_acc = accuracy_score(y_train, train_class_preds)\n","lr_train_prec = precision_score(y_train, train_class_preds)\n","lr_train_rec = recall_score(y_train, train_class_preds)\n","lr_train_f1 = f1_score(y_train, train_class_preds)\n","\n","results = pd.DataFrame([['Logistic Regression', lr_train_acc,lr_train_prec,lr_train_rec, lr_train_f1,lr_train_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"R4yqWK1k9vq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for test data\n","lr_test_roc=roc_auc_score(y_test, test_class_preds)\n","lr_test_acc = accuracy_score(y_test, test_class_preds)\n","lr_test_prec = precision_score(y_test, test_class_preds)\n","lr_test_rec = recall_score(y_test, test_class_preds)\n","lr_test_f1 = f1_score(y_test, test_class_preds)\n","\n","results = pd.DataFrame([['Logistic Regression', lr_test_acc,lr_test_prec,lr_test_rec, lr_test_f1,lr_test_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"FPiHUZrP9z-e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"yl3Kh0yq92wz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"tpGjb2IG95Xu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">GridSearchCV is a popular method for hyperparameter tuning that combines grid search and cross-validation. Grid search will try every possible combination of the specified hyperparameters and their values, while cross-validation will evaluate the model performance using a different portion of the data. it can be computationally expensive as the number of combinations increase.\n","\n",">The precision and recall values for both \"Non-Interested\" (64% precision and 91% recall) and \"Interested\" (94% precision and 72% recall) classes are reasonably good, suggesting that the model is not making too many false positive or false negative predictions.\n","\n",">The GridSearchCV method has helped in optimizing the hyperparameters of the logistic regression algorithm, leading to improved performance on the dataset compared to the default parameters."],"metadata":{"id":"_CD71y5t988C"}},{"cell_type":"markdown","source":["<h2><b>2. K_nearest neighbours(KNN):\n"],"metadata":{"id":"AN04YFgM-Gaf"}},{"cell_type":"code","source":["# Import KNeighborsClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#Setup arrays to store training and test accuracies\n","neighbors = np.arange(1,15)\n","train_accuracy =np.empty(len(neighbors))\n","test_accuracy = np.empty(len(neighbors))\n","\n","for i,k in enumerate(neighbors):\n","    # Setup a knn classifier with k neighbors\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    \n","    # Fit the model\n","    knn.fit(X_train, y_train)\n","    \n","    # Compute accuracy on the training set\n","    train_accuracy[i] = knn.score(X_train, y_train)\n","    \n","    # Compute accuracy on the test set\n","    test_accuracy[i] = knn.score(X_test, y_test)"],"metadata":{"id":"rDuKIDlL-Os3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate plot\n","\n","plt.title('k-NN Varying number of neighbors')\n","plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n","plt.plot(neighbors, train_accuracy, label='Training accuracy')\n","plt.legend()\n","plt.xlabel('Number of neighbors')\n","plt.ylabel('Accuracy')\n","plt.show()"],"metadata":{"id":"FBvxxLy3-RtG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take k=4\n","\n","knn = KNeighborsClassifier(n_neighbors=4)\n","\n","# Fit the model\n","knn.fit(X_train,y_train)"],"metadata":{"id":"WYpDuRaM-UVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on the model\n","# Making predictions on train and test data\n","train_class_preds = knn.predict(X_train)\n","test_class_preds = knn.predict(X_test)"],"metadata":{"id":"9BPedbec-Wz2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"1-lSdml8-b3n"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Get the confusion matrix for train \n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_train, train_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"LbiLiXfK-ZIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the confusion matrix test\n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_test, test_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"ppjCAG1--fd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kn_train_roc=roc_auc_score(y_train, train_class_preds)\n","kn_train_acc = accuracy_score(y_train, train_class_preds)\n","kn_train_prec = precision_score(y_train, train_class_preds)\n","kn_train_rec = recall_score(y_train, train_class_preds)\n","kn_train_f1 = f1_score(y_train, train_class_preds)\n","\n","results = pd.DataFrame([['Random Forest', kn_train_acc,kn_train_prec,kn_train_rec, kn_train_f1,kn_train_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"hvqtLchz-kb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kn_test_roc=roc_auc_score(y_test, test_class_preds)\n","kn_test_acc = accuracy_score(y_test, test_class_preds)\n","kn_test_prec = precision_score(y_test, test_class_preds)\n","kn_test_rec = recall_score(y_test, test_class_preds)\n","kn_test_f1 = f1_score(y_test, test_class_preds)\n","\n","results = pd.DataFrame([['Random Forest', kn_test_acc,kn_test_prec,kn_test_rec, kn_test_f1,kn_test_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"GyzYVTUn-tyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"52aVIdDa-uj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"HY81ONVq-yng"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","Based on the results of the KNN algorithm:-\n"," \n"," >The KNN classifier has high precision and recall for both the \"Non-Interested\" and \"Interested\" classes, with 91% precision and 86% recall for the \"Non-Interested\" class and 85% precision and 91% recall for the \"Interested\" class. These results suggest that the model is making relatively few false positive and false negative predictions.\n","\n"," >The overall accuracy, average precision, recall, and F1-score are all good (88% accuracy and 88% average precision, recall, and F1-score).\n","The ROC AUC score is 88%.\n","\n",">The testing results show lower precision and recall compared to the training results, but still have a good accuracy, average precision, recall, and F1-score (81% accuracy and 81% average precision, recall, and F1-score)."],"metadata":{"id":"-VmeSKh5-1-1"}},{"cell_type":"markdown","source":["<h2><b>3. Random Forest Classifier:\n"],"metadata":{"id":"bdHLPRrR_Moa"}},{"cell_type":"code","source":["# Create an instance of the RandomForestClassifier\n","rf_model = RandomForestClassifier()\n","\n","# Fit the Algorithm\n","rf_model.fit(X_train,y_train)\n","\n","# Predict on the model\n","# Making predictions on train and test data\n","train_class_preds = rf_model.predict(X_train)\n","test_class_preds = rf_model.predict(X_test)"],"metadata":{"id":"8AwSlREt_UA8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating accuracy on train and test\n","train_accuracy = accuracy_score(y_train,train_class_preds)\n","test_accuracy = accuracy_score(y_test,test_class_preds)\n","\n","print(\"The accuracy on train dataset is\", train_accuracy)\n","print(\"The accuracy on test dataset is\", test_accuracy)"],"metadata":{"id":"NB_9pffw_Uxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"fVvMlefR_Z7m"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","\n","#confusion matrix for train\n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_train, train_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"NgRedmap_XKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix for train\n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_test, test_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"-Y98Bodm_dak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"Tat4HSbU_gLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"Q5Ph18qe_m8C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Based on the results of the RandomForest algorithm:- \n","\n",">The RandomForest algorithm has high precision (98%) and recall (98%) for non-interested customers in the training dataset. However, the precision and recall for non-interested customers are slightly lower in the testing dataset at 82% and 87%, respectively.\n","\n",">The F1-score for both non-interested and interested customers is high (98%) in the training dataset, but lower in the testing dataset at 85%. This indicates that the model is overfitting to the training dataset and not performing as well on new data.\n","\n",">The accuracy is high (98%) in the training dataset, but lower in the testing dataset at 85%. This is consistent with the F1-score results and suggests that the model is overfitting to the training dataset.\n","\n",">The average precision, recall, and F1-score are all high (98%) in the training dataset, but lower in the testing dataset at 85%. This is again consistent with the overfitting observed in the F1-score and accuracy results.\n","\n",">The ROC AUC score is also high (98%) in the training dataset, but lower in the testing dataset at 85%. This suggests that the model's ability to distinguish between positive and negative classes is still good, but not as good as the performance on the training dataset.\n","\n",">Hyperparameter tuning techniques can be used to attempt to improve the model's performance on the testing dataset and reduce the overfitting to the training dataset.\n","\n","In conclusion, the RandomForest algorithm shows a high level of performance on the training dataset but lower performance on the testing dataset, suggesting overfitting. Hyperparameter tuning techniques can be used to improve the model's generalization to new data."],"metadata":{"id":"Eo1vFYmW_qG5"}},{"cell_type":"markdown","source":["2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"bIvhwoEpACud"}},{"cell_type":"code","source":["# n_estimators-----> Number of trees\n","# max_depth--------> Maximum depth of trees\n","# min_samples_split------> Minimum number of samples required to split a node \n","# min_samples_leaf-------> Minimum number of samples required at each leaf node"],"metadata":{"id":"-EgHR8uSADoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., RandomForestCV)\n","# random forest model\n","randomForest = RandomForestClassifier(random_state=0)\n","parameters = {'n_estimators':[50,80,100],'max_depth':[4,6,8],\n","             'min_samples_split':[50,100,150],\n","             'min_samples_leaf':[40,50]\n","             }\n","# Fit the Algorithm\n","rf_grid= GridSearchCV(randomForest, parameters, scoring='f1', cv=3)\n","rf_grid.fit(X_train,y_train)"],"metadata":{"id":"gngeZWfmAHBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model best parameters\n","print(f'The best fit is found to be {rf_grid.best_params_}')"],"metadata":{"id":"VKd3R7T0AKcF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on the model\n","# Making predictions on train and test data\n","train_class_preds = rf_grid.predict(X_train)\n","test_class_preds = rf_grid.predict(X_test)"],"metadata":{"id":"pCBWEeOFAM3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Get the confusion matrix for train \n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_train, train_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"uqNLd9E7AQCU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the confusion matrix test\n","\n","labels = ['Non_Interested', 'Interseted']\n","cm = confusion_matrix(y_test, test_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"xWnukpkUASyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for train data\n","rf_train_roc=roc_auc_score(y_train, train_class_preds)\n","rf_train_acc = accuracy_score(y_train, train_class_preds)\n","rf_train_prec = precision_score(y_train, train_class_preds)\n","rf_train_rec = recall_score(y_train, train_class_preds)\n","rf_train_f1 = f1_score(y_train, train_class_preds)\n","\n","results = pd.DataFrame([['Logistic Regression', rf_train_acc,rf_train_prec,rf_train_rec, rf_train_f1,rf_train_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"eBpFdoIdAVmc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for test data\n","rf_test_roc=roc_auc_score(y_test, test_class_preds)\n","rf_test_acc = accuracy_score(y_test, test_class_preds)\n","rf_test_prec = precision_score(y_test, test_class_preds)\n","rf_test_rec = recall_score(y_test, test_class_preds)\n","rf_test_f1 = f1_score(y_test, test_class_preds)\n","\n","results = pd.DataFrame([['Random Forest', rf_test_acc,rf_test_prec,rf_test_rec, rf_test_f1,rf_test_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"jTgooGimAZPK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"mGvYuoXdAdsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"Kg1FsmKIAgYw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>Which hyperparameter optimization technique have you used and why?\n","\n",">GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n","\n",">our goal should be to find the best hyperparameters values to get the perfect prediction results from our model. But the question arises, how to find these best sets of hyperparameters? One can try the Manual Search method, by using the hit and trial process and can find the best hyperparameters which would take huge time to build a single model.\n","\n",">For this reason, methods like Random Search, GridSearch were introduced. Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved.\n","\n",">In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n","\n",">That's why I have used GridsearCV method for hyperparameter optimization.\n","\n"],"metadata":{"id":"0P_fx-l7Alo4"}},{"cell_type":"markdown","source":["#####<b>Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","After hypertunning of randomforest algorithm:-\n","\n"," >For training dataset, Non-Interested customer has a precision of 71%, recall of 90% and f1-score of 79%. For Interested customer, precision is 92%, recall is 76% and f1-score is 83%.\n","\n"," >The accuracy is 82% and average precision, recall & f1-score are 82%, 83% and 81% respectively with a roc auc score of 82%. For testing dataset, Non-interested customer has a precision of 71%, recall of 90% and f1-score of 80%.\n","\n"," >For Interested customer, precision is 92%, recall is 76% and f1-score is 83%.The accuracy is 81% and average precision, recall & f1-score are 84%, 81% and 81% respectively with a roc auc score of 81%."],"metadata":{"id":"xKAqUASwBA9N"}},{"cell_type":"markdown","source":["<h1><b>4. XgBoost Classifier:"],"metadata":{"id":"kQBigdCbBWmp"}},{"cell_type":"code","source":["# ML Model - 4 Implementation\n","xg_model = XGBClassifier()\n","\n","# Fit the Algorithm\n","xg_models=xg_model.fit(X_train,y_train)\n","\n","# Predict on the model\n","# Making predictions on train and test data\n","train_class_preds = xg_models.predict(X_train)\n","test_class_preds = xg_models.predict(X_test)"],"metadata":{"id":"A0UofpU1BaFV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"3xaPlU3IBeO5"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Get the confusion matrix for train \n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_train, train_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix: XgBoost Classifier')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"dS1_WCEHBe2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the confusion matrix test\n","\n","labels = ['Non_Interested', 'Interested']\n","cm = confusion_matrix(y_test, test_class_preds)\n","print(cm)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix:  XgBoost Classifier')\n","ax.xaxis.set_ticklabels(labels)\n","ax.yaxis.set_ticklabels(labels)"],"metadata":{"id":"sIuXDvbiBhbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"cwCHlJZ2BkKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"1GtDnoRABmsn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Based on the results of the Xgboost algorithm:-\n","\n"," >For training dataset, Non-Interested customer has a precision of 74%, recall of 89% and f1-score of 81%. For Interested customer, precision is 90%, recall is 78% and f1-score is 84%.\n","\n"," >The accuracy is 82% and average precision, recall & f1-score are 82%, 83% and 82% respectively with a ROC AUC score of 82%.\n","\n"," >For testing dataset, Non-interested customer has a precision of 75%, recall of 89% and f1-score of 81%. For Interested customer, precision is 90%, recall is 78% and f1-score is 84%.\n","\n"," >The accuracy is 88% and average precision, recall & f1-score are 84%, 83% and 83% respectively with a ROC AUC score of 82%."],"metadata":{"id":"WFLOlq_8Bsso"}},{"cell_type":"markdown","source":["#####<b>2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"QEisTJccB7QL"}},{"cell_type":"code","source":["# ML Model - 4 Implementation with hyperparameter optimization techniques (RandomSearchCV)\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from xgboost import XGBClassifier\n","\n","# Set up the XGBoost classifier\n","xgb = XGBClassifier(random_state=0)\n","\n","# Define the hyperparameter search space\n","parameters = {'n_estimators': [50, 80, 100],\n","              'max_depth': [4, 6, 8],\n","              'min_samples_split': [50, 100, 150],\n","              'min_samples_leaf': [40, 50]}\n","\n","# Use RandomizedSearchCV to find the best hyperparameters\n","random_search = RandomizedSearchCV(xgb, parameters, scoring='roc_auc', cv=5)\n","\n","# Fit the model on the training data\n","random_search.fit(X_train, y_train)"],"metadata":{"id":"usiUQE2gCAjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model best parameters\n","print(f'The best fit is found to be {random_search.best_params_}')"],"metadata":{"id":"4XQkRcSABpyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on the model\n","# Making predictions on train and test data\n","train_class_preds = random_search.predict(X_train)\n","test_class_preds = random_search.predict(X_test)\n"],"metadata":{"id":"yJ6kYv8JAi3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for train data\n","Xgb_train_roc=roc_auc_score(y_train, train_class_preds)\n","Xgb_train_acc = accuracy_score(y_train, train_class_preds)\n","Xgb_train_prec = precision_score(y_train, train_class_preds)\n","Xgb_train_rec = recall_score(y_train, train_class_preds)\n","Xgb_train_f1 = f1_score(y_train, train_class_preds)\n","\n","results = pd.DataFrame([['XGBoost Classifier', Xgb_train_acc,Xgb_train_prec,Xgb_train_rec, Xgb_train_f1,Xgb_train_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])"],"metadata":{"id":"i8TXc_imCJmz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result dataframe for test data\n","Xgb_test_roc=roc_auc_score(y_test, test_class_preds)\n","Xgb_test_acc = accuracy_score(y_test, test_class_preds)\n","Xgb_test_prec = precision_score(y_test, test_class_preds)\n","Xgb_test_rec = recall_score(y_test, test_class_preds)\n","Xgb_test_f1 = f1_score(y_test, test_class_preds)\n","\n","results = pd.DataFrame([['XGBoost Classifier', Xgb_test_acc,Xgb_test_prec,Xgb_test_rec, Xgb_test_f1,Xgb_test_roc]],\n","               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n","results"],"metadata":{"id":"nO5xZJ8aCMmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for train data\n","print(metrics.classification_report(train_class_preds, y_train))\n","print(\" \")\n","\n","print(\"roc_auc_score_train\")\n","print(metrics.roc_auc_score(y_train, train_class_preds))"],"metadata":{"id":"tYpzOeRHCO7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hypertuned report metrics for test data\n","print(metrics.classification_report(test_class_preds, y_test))\n","print(\" \")\n","\n","print(\"roc_auc_score_test\")\n","print(metrics.roc_auc_score(y_test, test_class_preds))"],"metadata":{"id":"iBQzeU6sCRKZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","After hypertunning following conclusions are:\n","\n"," >For training dataset, Non-Interested customer has a precision of 78%, recall of 90% and f1-score of 83%. For Interested customer, precision is 91%, recall is 80% and f1-score is 84%.\n","\n"," >The accuracy is 84% and average precision, recall & f1-score are 84%, 85% and 84% respectively with a ROC AUC score of 84%.\n","\n"," >For testing dataset, Non-interested customer has a precision of 78%, recall of 89% and f1-score of 83%. For Interested customer, precision is 91%, recall is 80% and f1-score is 85%.\n","\n"," >The accuracy is 84% and average precision, recall & f1-score are 84%, 85% and 84% respectively with a ROC AUC score of 84%."],"metadata":{"id":"tF1AywEiCYwa"}},{"cell_type":"markdown","source":["#####<B>1. Which Evaluation metrics did you consider for a positive business impact and why?\n","\n",">In conclusion, when both false negatives and false positives need to be minimized, the f1-score should be considered as it balances between precision and recall. In such cases, recall is usually given more importance, but precision should not be neglected. The goal is to have a high recall and moderate f1-score."],"metadata":{"id":"BmNt0IvpCq10"}},{"cell_type":"markdown","source":["#####<b>2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"6As0b0ciCy44"}},{"cell_type":"code","source":["from prettytable import PrettyTable\n","\n","# Summarizing the results obtained\n","test = PrettyTable(['Sl. No.','Model','Train_Accuracy','Test_Accuracy', 'Train_Precision','Test_Precision','Train_Recall','Test_Recall','Train_F1_score','Test_F1_score'])\n","test.add_row(['1','Logistic Regression',lr_train_acc,lr_test_acc,lr_train_prec,lr_test_prec,lr_train_rec,lr_test_rec,lr_train_f1,lr_test_f1])\n","test.add_row(['2','k_nearest neighbours',kn_train_acc,kn_test_acc,kn_train_prec,kn_test_prec,kn_train_rec,kn_test_rec,kn_train_f1,kn_test_f1])\n","test.add_row(['3','Random Forest',rf_train_acc,rf_test_acc,rf_train_prec,rf_test_prec,rf_train_rec,rf_test_rec,rf_train_f1,rf_test_f1])\n","test.add_row(['4','XGboost Classsifier',Xgb_train_acc,Xgb_test_acc,Xgb_train_prec,Xgb_test_prec,Xgb_train_rec,Xgb_test_rec,Xgb_train_f1,Xgb_test_f1])\n","\n","print(test)"],"metadata":{"id":"owT9G9j8C3aS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting Recall scores\n","\n","ML_models = ['Logistic Regression','K Nearest Neighbors','Random Forests','XG Boost']\n","train_recalls = [lr_train_rec,kn_train_rec,rf_train_rec,Xgb_train_rec]\n","test_recalls = [lr_test_rec,kn_test_rec,rf_test_rec,Xgb_test_rec]\n","  \n","X_axis = np.arange(len(ML_models))\n","\n","plt.figure(figsize=(10,5))\n","plt.barh(X_axis - 0.2, train_recalls, 0.4, label = 'Train Recall')\n","plt.barh(X_axis + 0.2, test_recalls, 0.4, label = 'Test Recall')\n","  \n","plt.yticks(X_axis,ML_models)\n","plt.xlabel(\"Recall score\")\n","plt.title(\"Recall score for each model\")\n","plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',title='Legend')\n","plt.show()"],"metadata":{"id":"VrWR9g1HC-tB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####<b>3. Explain the model which you have used and the feature importance using any model explainability tool?\n","\n",">We will use Shapley values to explain the black box model(Random Forest).\n","\n",">It shows the contribution or the importance of each feature on the prediction of the model. This makes it more explainable."],"metadata":{"id":"-XE6ci4RDBCa"}},{"cell_type":"markdown","source":["<h1><b>Conclusion"],"metadata":{"id":"dgRS2hCCDPEq"}},{"cell_type":"markdown","source":["<b>Here are the key points from the conclusion of the Health Insurance Cross Sell Prediction project:\n","\n"," * The goal of the project was to identify existing Health Insurance customers who are likely to be interested in purchasing Vehicle Insurance.\n","\n"," * The Gradient Boosting algorithm provided the best overall performance in terms of accuracy, precision, recall, and F1 score.\n"," \n"," * The model achieved an accuracy of 84% and an average precision, recall, and F1 score of 84%, 85%, and 84%, respectively.\n","\n"," * Other algorithms such as Random Forest, XGBoost, KNN, and Logistic Regression also performed well, with accuracy scores ranging from 80% to 82%, but did not outperform Gradient Boosting.\n","\n"," * The findings suggest that the Gradient Boosting algorithm is an effective machine learning approach for predicting customer interest in a vehicle's insurance.\n","\n"," * The model could be used to inform targeted marketing campaigns for the insurance company.\n","\n"," * Exploratory Data Analysis revealed that more males were interested in Vehicle Insurance.\n"," \n"," * Feature engineering was used to transform categorical variables into numerical variables.\n"," \n"," * The dataset consisted of 381109 observations and 12 features.\n"," \n"," * Evaluation metrics used for the models included precision, recall, f1-score, accuracy, average precision, and ROC AUC score.\n"," \n"," * Hyperparameter tuning was used to improve the performance of the models."],"metadata":{"id":"FfTPUjRhDSxV"}},{"cell_type":"markdown","source":["<H2><b>*Hurrah! You have successfully completed your Machine Learning Capstone Project !!!*"],"metadata":{"id":"OxBjmBTmEGce"}}]}